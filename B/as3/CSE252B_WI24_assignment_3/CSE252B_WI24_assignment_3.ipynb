{"cells":[{"cell_type":"markdown","metadata":{"id":"w_HBDk1YUozT"},"source":["# CSE 252B: Computer Vision II, Winter 2024 â€“ Assignment 3\n"]},{"cell_type":"markdown","metadata":{"id":"nxju0ayEWQ90"},"source":["Instructor: Ben Ochoa\n","\n","Assignment Due: Wed, Feb 21, 11:59 PM"]},{"cell_type":"markdown","metadata":{"id":"fE60HjYqWkKs"},"source":["**Name: Xiao Nan**\n","\n","**PID: A69027384**"]},{"cell_type":"markdown","metadata":{"id":"caRXX_tyUozX"},"source":["## Instructions\n","* Review the academic integrity and collaboration policies on the course\n","website.\n","* This assignment must be completed individually.\n","* All solutions must be written in this notebook.\n","* Math must be done in Markdown/$\\LaTeX$.\n","* You must show your work and describe your solution.\n","* Programming aspects of this assignment must be completed using Python in this notebook.\n","* Your code should be well written with sufficient comments to understand, but there is no need to write extra markdown to describe your solution if it is not explictly asked for.\n","* This notebook contains skeleton code, which should not be modified (this is important for standardization to facilate efficient grading).\n","* You may use python packages for basic linear algebra, but you may not use functions that directly solve the problem. If you are uncertain about using a specific package, function, or method, then please ask the instructional staff whether it is allowable.\n","* **You must submit this notebook as an .ipynb file, a .py file, and a .pdf file on Gradescope.**\n","    - You may directly export the notebook as a .py file.  You may use [nbconvert](https://nbconvert.readthedocs.io/en/latest/install.html) to convert the .ipynb file to a .py file using the following command\n","    `jupyter nbconvert --to script filename.ipynb`\n","    - There are two methods to convert the notebook to a .pdf file.\n","        - You may first export the notebook as a .html file, then print the web page as a .pdf file.\n","        - If you have XeTeX installed, then you may directly export the notebook as a .pdf file.  You may use [nbconvert](https://nbconvert.readthedocs.io/en/latest/install.html) to convert a .ipynb file to a .pdf file using the following command\n","        `jupyter nbconvert --allow-chromium-download --to webpdf filename.ipynb`\n","    - **You must ensure the contents in each cell (e.g., code, output images, printed results, etc.) are clearly visible, and are not cut off or partially cropped in the .pdf file.**\n","    - Your code and results must remain inline in the .pdf file (do not move your code to an appendix).\n","    - **While submitting on gradescope, you must assign the relevant pages in the .pdf file submission for each problem.**\n","* It is highly recommended that you begin working on this assignment early."]},{"cell_type":"markdown","metadata":{"id":"EZqJwYx5UozY"},"source":["## Problem 1 (Programming):  Estimation of the Camera Pose - Outlier rejection (20 points)\n","  Download input data from the course website.  The file\n","  `hw3_points3D.txt` contains the coordinates of 60 scene points\n","  in 3D (each line of the file gives the $\\tilde{X}_i$, $\\tilde{Y}_i$,\n","  and $\\tilde{Z}_i$ inhomogeneous coordinates of a point).  The file\n","  `hw3_points2D.txt` contains the coordinates of the 60\n","  corresponding image points in 2D (each line of the file gives the\n","  $\\tilde{x}_i$ and $\\tilde{y}_i$ inhomogeneous coordinates of a\n","  point).  The corresponding 3D scene and 2D image points contain both\n","  inlier and outlier correspondences.  For the inlier correspondences,\n","  the scene points have been randomly generated and projected to image\n","  points under a camera projection matrix (i.e., $\\boldsymbol{\\mathrm{x}}_i =\n","  \\mathtt{P} \\boldsymbol{\\mathrm{X}}_i$), then noise has been added to the\n","  image point coordinates.\n","\n","  The camera calibration matrix was calculated for a $1280 \\times 720$\n","  sensor and $45\\circ$ horizontal field of view lens.  The\n","  resulting camera calibration matrix is given by\n","\n","  $\\mathtt{K} = \\begin{bmatrix}\n","      1545.0966799187809 & 0 & 639.5\\\\\n","      0 & 1545.0966799187809 & 359.5\\\\\n","      0 & 0 & 1\n","    \\end{bmatrix}$\n","    \n","  For each image point $\\boldsymbol{\\mathrm{x}} = (x, y, w)^\\top = (\\tilde{x},\n","  \\tilde{y}, 1)^\\top$, calculate the point in normalized coordinates\n","  $\\hat{\\boldsymbol{\\mathrm{x}}} = \\mathtt{K}^{-1} \\boldsymbol{\\mathrm{x}}$.\n","\n","  Determine the set of inlier point correspondences using the\n","  M-estimator Sample Consensus (MSAC) algorithm, where the maximum\n","  number of attempts to find a consensus set is determined adaptively.\n","  For each trial, use the 3-point algorithm of Finsterwalder (as\n","  described in the paper by Haralick et al.) to estimate the camera pose (i.e.,\n","  the rotation $\\mathtt{R}$ and translation $\\boldsymbol{\\mathrm{t}}$ from the\n","  world coordinate frame to the camera coordinate frame), resulting in\n","  up to 4 solutions, and calculate the error and cost for each\n","  solution.  Note that the 3-point algorithm requires the 2D points in\n","  normalized coordinates, not in pixel coordinates.  Calculate the\n","  projection error, which is the (squared) distance between projected\n","  points (the points in 3D projected under the normalized camera projection\n","  matrix $\\hat{\\mathtt{P}} = [\\mathtt{R} \\,|\\, \\boldsymbol{\\mathrm{t}}]$) and the\n","  measured points in normalized coordinates (hint: the error tolerance\n","  is simpler to calculate in pixel coordinates using $\\mathtt{P} =\n","  \\mathtt{K} [\\mathtt{R} \\,|\\, \\boldsymbol{\\mathrm{t}}]$ than in normalized\n","  coordinates using $\\hat{\\mathtt{P}} = [\\mathtt{R} \\,|\\,\n","  \\boldsymbol{\\mathrm{t}}]$. You can avoid doing covariance propagation). There\n","  must be at least **40 inlier correspondences**.\n","\n","  \n","  Hint: this problem has codimension 2.\n","\n","\n","#### Report your values for:\n"," * the probability $p$ that as least one of the random samples does not contain any outliers (prob of all-inlier random subset)\n"," * the probability $\\alpha$ that a given point is an inlier (inlier prob within a subset)\n"," * the resulting number of inliers\n"," * the number of attempts to find the consensus set"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180,"status":"ok","timestamp":1707281294261,"user":{"displayName":"Siddharth Satyam","userId":"01034429838794457318"},"user_tz":480},"id":"R7jqJN6yUozY","outputId":"4b4edac3-e677-4b03-d161-779022caedca"},"outputs":[{"name":"stdout","output_type":"stream","text":["x is (2, 60)\n","X is (3, 60)\n","K =\n","[[1.54509668e+03 0.00000000e+00 6.39500000e+02]\n"," [0.00000000e+00 1.54509668e+03 3.59500000e+02]\n"," [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"]}],"source":["import numpy as np\n","import time\n","\n","def homogenize(x):\n","    # converts points from inhomogeneous to homogeneous coordinates\n","    return np.vstack((x, np.ones((1, x.shape[1]))))\n","\n","def dehomogenize(x):\n","    # converts points from homogeneous to inhomogeneous coordinates\n","    return x[:-1] / x[-1]\n","\n","def normalize(K, x):\n","    # map the 2D points in pixel coordinates to the 2D points in normalized coordinates\n","    # Inputs:\n","    #   K - camera calibration matrix\n","    #   x - 2D points in pixel coordinates\n","    # Output:\n","    #   pts - 2D points in normalized coordinates\n","    return np.linalg.inv(K) @ x\n","\n","\n","# load data\n","x0 = np.loadtxt('hw3_points2D.txt').T\n","X0 = np.loadtxt('hw3_points3D.txt').T\n","print('x is', x0.shape)\n","print('X is', X0.shape)\n","\n","K = np.array([[1545.0966799187809, 0, 639.5],\n","              [0, 1545.0966799187809, 359.5],\n","              [0, 0, 1]])\n","\n","print('K =')\n","print(K)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"5nUCO62NUoza"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final minimal cost: 208.0123498384926\n","took 0.04157686233520508 secs\n","iterations: 42\n","inlier count: 42\n","MSAC Cost: 208.012349838\n","P = \n","[[  0.28909222  -0.68063079   0.6731771    6.69890465]\n"," [  0.6600831   -0.36757721  -0.65511625   7.38891396]\n"," [  0.69333685   0.63374184   0.34300916 175.72248156]]\n","inliers:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49]\n","p = 0.999\n","alpha = 0.95\n","tolerance = 5.991464547107979\n","num_inliers = 42\n","num_attempts = 42\n"]}],"source":["from scipy.stats import chi2\n","import random\n","\n","def project_and_get_error(P, x, X, K):\n","    X_homo = homogenize(X)\n","    x_img_proj_homo = K @ P @ X_homo\n","    x_img_proj = dehomogenize(x_img_proj_homo) \n","    error = np.sum((x - x_img_proj)**2, axis=0)\n","    return error\n","\n","def compute_MSAC_cost(x, tol, error):\n","    # Inputs:\n","    #    P - normalized camera projection matrix\n","    #    x - 2D groundtruth image points\n","    #    X - 3D groundtruth scene points\n","    #    K - camera calibration matrix\n","    #    tol - reprojection error tolerance\n","    #    error - pre-computed projection error\n","    #\n","    # Output:\n","    #    cost - total projection error\n","    #    inlier_ind - inlier indices\n","    inlier_ind = []\n","    cost = 0\n","    count = x.shape[1]\n","    for n in range(count):\n","        if (error[n] <= tol):\n","            cost += error[n]\n","            inlier_ind.append(n)\n","        else:\n","            cost += tol\n","    return cost, inlier_ind\n","\n","np.random.seed(38)\n","def choose_random_column_indices(array_2d, num_columns_to_choose):\n","    \"\"\"\n","    Chooses a random sample of columns from a 2D NumPy array.\n","    \n","    Parameters:\n","        array_2d (ndarray): The input 2D NumPy array.\n","        num_columns_to_choose (int): The number of columns to choose randomly.\n","        \n","    Returns:\n","        random_column_indices: Indices of the randomly chosen columns.\n","    \"\"\"\n","    # Number of columns in the array\n","    num_columns = array_2d.shape[1]\n","    # Randomly choose column indices\n","    random_column_indices = np.random.choice(num_columns, size=num_columns_to_choose, replace=False)\n","    return random_column_indices\n","\n","def solve_cubic(a, b, c, d):\n","    \"\"\"\n","    Solves a cubic equation of the form ax^3 + bx^2 + cx + d = 0\n","    \n","    Parameters:\n","        a, b, c, d (float): Coefficients of the cubic equation.\n","        \n","    Returns:\n","        ndarray: An array containing the roots of the cubic equation.\n","    \"\"\"\n","    coefficients = [a, b, c, d]\n","    roots = np.roots(coefficients)\n","    return roots\n","\n","def solve_quadratic(b, c, d):\n","    \"\"\"\n","    Solves a cubic equation of the form bx^2 + cx + d = 0\n","    \n","    Parameters:\n","        b, c, d (float): Coefficients of the quadratic equation.\n","        \n","    Returns:\n","        ndarray: An array containing the roots of the quadratic equation.\n","    \"\"\"\n","    coefficients = [b, c, d]\n","    roots = np.roots(coefficients)\n","    return roots\n","\n","def solveLambda(d1, d2, d3, cosAlpha, cosBeta, cosGamma, sin2Alpha, sin2Beta, sin2Gamma, a, b, c):\n","    g = c**2 * (c**2 * sin2Beta - b**2 * sin2Gamma)\n","    h = b**2 * (b**2 - a**2) * sin2Gamma + c**2 * (c**2 + 2 * a**2) * sin2Beta + 2 * b**2 * c**2 * (cosAlpha*cosBeta*cosGamma-1)\n","    i = b**2 * (b**2 - c**2) * sin2Alpha + a**2 * (a**2 + 2 * c**2) * sin2Beta + 2 * a**2 * b**2 * (cosAlpha*cosBeta*cosGamma-1)\n","    j = a**2 * (a**2 * sin2Beta - b**2 * sin2Alpha)\n","    roots = solve_cubic(g, h, i, j)\n","    roots = np.real(roots[np.isreal(roots)])\n","    return roots[0]\n","\n","\n","def get_camera_points(x, X, K):\n","    # normalize to normalized coordinates first\n","    x_normal_homo = np.linalg.inv(K) @ homogenize(x)\n","    # unitization\n","    d_123 = x_normal_homo / (np.sign(x_normal_homo[-1, :])*np.linalg.norm(x_normal_homo, axis=0))\n","    # solve lambda\n","    d1, d2, d3 = d_123[:, 0], d_123[:, 1], d_123[:, 2]\n","    cosAlpha, cosBeta, cosGamma = d2@d3, d1@d3, d1@d2\n","    sin2Alpha, sin2Beta, sin2Gamma = 1-cosAlpha**2, 1-cosBeta**2, 1-cosGamma**2\n","    a, b, c = np.linalg.norm(X[:,1]-X[:,2]), np.linalg.norm(X[:,2]-X[:,0]), np.linalg.norm(X[:,1]-X[:,0])\n","    a2, b2, c2 = a**2, b**2, c**2\n","    lambda0 = solveLambda(d1, d2, d3, cosAlpha, cosBeta, cosGamma, sin2Alpha, sin2Beta, sin2Gamma, a, b, c)\n","    # solve u,v, and finally solving s\n","    s = []\n","    A, B, C, D, E, F = b2 * (lambda0 + 1), -b2 * cosAlpha, ( b2 - a2 - lambda0 * c2 ), -b2 * lambda0 * cosGamma, cosBeta * ((a2 + lambda0 * c2)), ( lambda0 * (b2 - c2) - a2 )\n","    p_root, q_root = (B**2) - A*C, (E**2) - C*F # in case u has no solution\n","    if ((p_root < 0) or (q_root < 0)):\n","        return []\n","    p, q = np.sqrt(p_root), np.sign(B*E - C*D) * np.sqrt(q_root) \n","    m, n = [(-B + p) / C, (-B - p) / C], [-(E - q) / C, -(E + q) / C]\n","    for j in range(len(m)):\n","        mj, nj = m[j], n[j]\n","        Au = b2 - (mj**2) * c2\n","        Bu = 2 * ((c2 * (cosBeta - nj) * mj) - (b2 * cosGamma))\n","        Cu = -c2 * (nj**2) + (2 * c2 * nj) * cosBeta + b2 - c2\n","        # solve slack variables u,v\n","        us = solve_quadratic(Au, Bu, Cu)\n","        us = np.real(us[np.isreal(us)]) # solve for u\n","        # back-projection to camera frame\n","        for u in us:\n","            v = u * mj + nj\n","            # print(\"My b, v, cosBeta: {}, {}, {}\".format(b, v, cosBeta))\n","            s1 = np.sqrt(b2 / (1 + (v**2) - (2*v*cosBeta))) # remember to square b !!!\n","            s2 = u * s1\n","            s3 = v * s1\n","            # print(\"My s1, s2, s3: {}, {}, {}\".format(s1, s2, s3))\n","            if (s1 > 0 and s2 > 0 and s3 > 0):\n","                s.append([s1, s2, s3])  \n","    \n","    # get camera coordinates (up to 4 solutions)\n","    cam_coors = []\n","    for s_123 in s:\n","        cam_coor = np.zeros((3,3))\n","        cam_coor[:, 0], cam_coor[:, 1], cam_coor[:, 2] = s_123[0]*d1, s_123[1]*d2, s_123[2]*d3\n","        cam_coors.append(cam_coor)\n","    return cam_coors\n","\n","def umeyama(cam_coor, X):\n","    # cam_coor, X: Inhomogeneious camera and world coordinates\n","    cam_mean, X_mean = np.mean(cam_coor, axis=1), np.mean(X, axis=1)\n","    d, n = cam_coor.shape[0], cam_coor.shape[1]\n","    S = np.zeros((d,d))\n","    for j in range(n):\n","        S += np.outer(cam_coor[:, j] - cam_mean, X[:, j] - X_mean)\n","    U, sig, Vt = np.linalg.svd(S)\n","    if (np.linalg.det(U) * np.linalg.det(Vt.T) < 0):\n","        I = np.eye(3)\n","        I[-1, -1] = -1\n","        R = U @ I @ Vt # 3x3\n","    else:\n","        R = U @ Vt\n","    T = cam_mean - R @ X_mean # 3x1\n","    # load projection matrix and return\n","    P = np.zeros((3,4))\n","    P[:,:3], P[:,3] = R, T\n","    return P\n","\n","def finsterWadler_get_pose(x, X, K):\n","    # estimate pose using FW algorithm (P3P)\n","    cam_coors = get_camera_points(x, X, K)\n","    PList = []\n","    for cam_coor in cam_coors:\n","        P = umeyama(cam_coor, X)\n","        PList.append(P)\n","    return PList\n","\n","def determine_inliers(x, X, K, thresh, tol, p):\n","    # Inputs:\n","    #    x - 2D inhomogeneous image points\n","    #    X - 3D inhomogeneous scene points\n","    #    K - camera calibration matrix\n","    #    thresh - cost threshold\n","    #    tol - reprojection error tolerance\n","    #    p - probability that as least one of the random samples does not contain any outliers\n","    #\n","    # Output:\n","    #    consensus_min_cost - final cost from MSAC\n","    #    consensus_min_cost_model - camera projection matrix P\n","    #    inliers - list of indices of the inliers corresponding to input data\n","    #    trials - number of attempts taken to find consensus set\n","\n","    \"\"\"your code here\"\"\"\n","    max_trials = np.inf\n","    consensus_min_cost = np.inf\n","    n = x.shape[1]\n","    s = 3 # sample size = 3\n","    trials = 0\n","\n","    inliers = [0]*39\n","    while (len(inliers) < 40): # get at least 40 inliers\n","        while ((trials < max_trials) and (consensus_min_cost > thresh)): # \"for\" loop's number of rounds executing cannot be updated. So use \"while\" instead\n","            samp_inds = choose_random_column_indices(X, s)\n","            X_samp = X[:, samp_inds]\n","            x_samp = x[:, samp_inds]\n","\n","            # for a given set of correspondances, there can be multiple camera coordinates, hence multiple poses (models) possible\n","            PList = finsterWadler_get_pose(x_samp, X_samp, K) \n","\n","            # evaluate error for each possible pose\n","            for P in PList:\n","                error = project_and_get_error(P, x, X, K)\n","                # print(error, tol)\n","                cost, inlier_ind = compute_MSAC_cost(x, tol, error)\n","                # print(cost, inlier_ind)\n","                if (cost < consensus_min_cost):\n","                    consensus_min_cost = cost\n","                    consensus_min_cost_model = P\n","                    w = len(inlier_ind) / n\n","                    # print(p, w, s)\n","                    max_trials = np.log(1-p) / np.log(1-(w**s))\n","                    # print(max_trials)\n","            trials += 1\n","        error_min = project_and_get_error(consensus_min_cost_model, x, X, K)\n","        cost_min, inliers = compute_MSAC_cost(x, tol, error_min)\n","\n","    print(\"Final minimal cost: {}\".format(cost_min))\n","    return consensus_min_cost, consensus_min_cost_model, inliers, trials\n","\n","\n","# MSAC parameters\n","thresh = 100\n","codim, alpha, sigma = 2, 0.95, 1\n","tol = chi2.ppf(alpha, codim) * sigma\n","p = 0.999\n","\n","tic = time.time()\n","\n","cost_MSAC, P_MSAC, inliers, trials = determine_inliers(x0, X0, K, thresh, tol, p)\n","\n","# choose just the inliers\n","x = x0[:, inliers]\n","X = X0[:, inliers]\n","\n","toc = time.time()\n","time_total = toc-tic\n","\n","# display the results\n","print(f'took {time_total} secs')\n","print(f'iterations: {trials}')\n","print(f'inlier count: {len(inliers)}')\n","print(f'MSAC Cost: {cost_MSAC:.9f}')\n","print('P = ')\n","print(P_MSAC)\n","print('inliers: ', inliers)\n","\n","# display required values\n","print(f\"p = {p}\")\n","print(f\"alpha = {alpha}\")\n","print(f\"tolerance = {tol}\")\n","print(f\"num_inliers = {len(inliers)}\")\n","print(f\"num_attempts = {trials}\")"]},{"cell_type":"markdown","metadata":{"id":"vZeyvp8dUozb"},"source":["## Problem 2 (Programming): Estimation of the Camera Pose - Linear Estimate (30 points)\n","  Estimate the normalized camera projection matrix\n","  $\\hat{\\mathtt{P}}_\\text{linear} = [\\mathtt{R}_\\text{linear} \\,|\\,\n","  \\boldsymbol{\\mathrm{t}}_\\text{linear}]$ from the resulting set of inlier\n","  correspondences using the linear estimation method (based on the\n","  EPnP method) described in lecture. Report the resulting\n","  $\\mathtt{R}_\\text{linear}$ and $\\boldsymbol{\\mathrm{t}}_\\text{linear}$."]},{"cell_type":"code","execution_count":87,"metadata":{"id":"0UZB0R2sUozb","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["took 0.003988504409790039 secs\n","R_linear = \n","[[ 0.28064893 -0.68881831  0.6684052 ]\n"," [ 0.65915863 -0.36787693 -0.65587839]\n"," [ 0.6976719   0.62465663  0.35079626]]\n","t_linear = \n","[  5.79182291   7.33117459 177.06840638]\n"]}],"source":["import time\n","\n","def sum_of_square_projection_error(P, x, X, K):\n","    # Inputs:\n","    #    P - normalized camera projection matrix\n","    #    x - 2D groundtruth image points\n","    #    X - 3D groundtruth scene points\n","    #    K - camera calibration matrix\n","    #\n","    # Output:\n","    #    cost - Sum of squares of the reprojection error\n","    X_homo = homogenize(X)\n","    x_img_proj_homo = K @ P @ X_homo\n","    x_img_proj = dehomogenize(x_img_proj_homo) \n","    cost = np.sum((x - x_img_proj)**2, axis=0)\n","    return cost\n","\n","def umeyama(cam_coor, X):\n","    # cam_coor, X: Inhomogeneious camera and world coordinates\n","    cam_mean, X_mean = np.mean(cam_coor, axis=1), np.mean(X, axis=1)\n","    d, n = cam_coor.shape[0], cam_coor.shape[1]\n","    S = np.zeros((d,d))\n","    for j in range(n):\n","        S += np.outer(cam_coor[:, j] - cam_mean, X[:, j] - X_mean)\n","    U, sig, Vt = np.linalg.svd(S)\n","    if (np.linalg.det(U) * np.linalg.det(Vt.T) < 0):\n","        I = np.eye(3)\n","        I[-1, -1] = -1\n","        R = U @ I @ Vt # 3x3\n","    else:\n","        R = U @ Vt\n","    T = cam_mean - R @ X_mean # 3x1\n","    # load projection matrix and return\n","    P = np.zeros((3,4))\n","    P[:,:3], P[:,3] = R, T\n","    return R, T, P\n","\n","def estimate_camera_pose_linear(x, X, K):\n","    # Inputs:\n","    #    x - 2D inlier points\n","    #    X - 3D inlier points\n","    # Output:\n","    #    P - normalized camera projection matrix\n","    # normalize x\n","    x_normal = dehomogenize(np.linalg.inv(K) @ homogenize(x))\n","\n","    # compute world ctl points\n","    X_mean = np.mean(X, axis=1)\n","    X_cov = np.cov(X)\n","    Lambda, U = np.linalg.eigh(X_cov)\n","    Lambda, U = Lambda[::-1], U[:, ::-1]\n","    U = np.hstack([np.zeros((3,1)), U])\n","    C1234world = U + X_mean[:,None]\n","    C1world, C2world, C3world, C4world = C1234world[:, 0], C1234world[:, 1], C1234world[:, 2], C1234world[:, 3]\n","    \n","    # compute parameterizations\n","    n = x.shape[1]\n","    A = np.hstack([(C2world-C1world)[:, None], (C3world-C1world)[:, None], (C4world-C1world)[:, None]])\n","    A = np.tile(A, (n, 1))\n","    b = X.reshape(-1, order=\"F\")\n","    b = b - np.tile(C1world, n)\n","    alpha234 = np.zeros(3*n)\n","    for j in range(n):\n","        Aj = A[3*j:3*j+3, :]\n","        Aj_inv = np.linalg.inv(Aj)\n","        bj = b[3*j:3*j+3]\n","        alpha234[3*j:3*j+3] = Aj_inv @ bj\n","        alpha234[3*j] = alpha234[3*j]\n","\n","    # compute camera ctl points\n","    M = np.zeros((2*n, 12))\n","    for j in range(n):\n","        alphaj2, alphaj3, alphaj4 = alpha234[3*j], alpha234[3*j+1], alpha234[3*j+2]\n","        alphaj1 = 1 - alphaj2 - alphaj3 - alphaj4 \n","        xj, yj = x_normal[:, j][0], x_normal[:, j][1]\n","        alphaj = [alphaj1, alphaj2, alphaj3, alphaj4]\n","        for i in range(len(alphaj)):\n","            alphaji = alphaj[i]\n","            M[2*j, 3*i], M[2*j+1, 3*i+1], M[2*j, 3*i+2], M[2*j+1, 3*i+2] = alphaji, alphaji, -alphaji*xj, -alphaji*yj\n","    U, sig, Vt = np.linalg.svd(M)\n","    CCam = Vt[-1, :]\n","    C1cam = CCam[0:3][:, None]\n","    C2cam = CCam[3:6][:, None]\n","    C3cam = CCam[6:9][:, None]\n","    C4cam = CCam[9:][:, None]\n","\n","    # compute camera coordinates\n","    sigma2_X = np.trace(X_cov)\n","    alpha234_cols = np.reshape(alpha234, (3, -1), order='F')\n","    alpha2, alpha3, alpha4 = alpha234_cols[0, :], alpha234_cols[1, :], alpha234_cols[2, :]\n","    alpha1 = np.ones(n) - alpha2 - alpha3 - alpha4\n","    X_cam = alpha1*C1cam+alpha2*C2cam+alpha3*C3cam+alpha4*C4cam\n","    ZCam_mean = np.mean(X_cam[2, :])\n","    sigma2_Xcam = np.var(X_cam[0, :])+np.var(X_cam[1, :])+np.var(X_cam[2, :])\n","    beta = np.sqrt(sigma2_X / sigma2_Xcam)\n","    if(np.sign(ZCam_mean) < 0):\n","        beta = -beta\n","    X_cam = beta * X_cam\n","\n","    # umeyama alignment for camera pose matrix\n","    R, t, P = umeyama(X_cam, X)\n","    return P\n","\n","tic = time.time()\n","P_linear = estimate_camera_pose_linear(x, X, K)\n","toc = time.time()\n","time_total = toc - tic\n","\n","# display the results\n","print(f'took {time_total} secs')\n","print('R_linear = ')\n","print(P_linear[:, 0:3])\n","print('t_linear = ')\n","print(P_linear[:, -1])"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"65n13yXuUozb"},"source":["## Problem 3 (Programming): Estimation of the Camera Pose - Nonlinear Estimate (30 points)\n","  Use $\\mathtt{R}_\\text{linear}$ and $\\boldsymbol{\\mathrm{t}}_\\text{linear}$ as\n","  an initial estimate to an iterative estimation method, specifically the\n","  Levenberg-Marquardt algorithm, to determine the Maximum Likelihood\n","  estimate of the camera pose that minimizes the projection error\n","  under the normalized camera projection matrix $\\hat{\\mathtt{P}} = [\\mathtt{R}\n","  \\,|\\, \\boldsymbol{\\mathrm{t}}]$.  You must parameterize the camera rotation\n","  using the angle-axis representation $\\boldsymbol{\\omega}$ (where\n","  $[\\boldsymbol{\\omega}]_\\times = \\ln \\mathtt{R}$) of a 3D rotation,\n","  which is a 3-vector.\n","    \n","  Report the initial cost (i.e., cost at iteration 0) and the cost at the end\n","  of each successive iteration. Show the numerical values for the final\n","  estimate of the camera rotation $\\boldsymbol{\\omega}_\\text{LM}$ and\n","  $\\mathtt{R}_\\text{LM}$, and the camera translation\n","  $\\boldsymbol{\\mathrm{t}}_\\text{LM}$."]},{"cell_type":"code","execution_count":88,"metadata":{"id":"a4isFI81Uozc"},"outputs":[],"source":["from scipy.linalg import block_diag\n","\n","# Note that np.sinc is different than defined in class\n","def sinc(x):\n","    # Returns a scalar valued sinc value\n","    if (x==0):\n","        return 1\n","    else:\n","        return np.sin(x) / x\n","\n","def d_sinc(x):\n","    if (x==0):\n","        return 0\n","    else:\n","        return (np.cos(x) / x) - (np.sin(x) / (x**2))\n","    \n","def skew(w):\n","    # Returns the skew-symmetrix represenation of a vector\n","    w_skew = np.zeros((3, 3))\n","    w_skew[0, 1], w_skew[1, 0] = -w[2], w[2] \n","    w_skew[0, 2], w_skew[2, 0] = w[1], -w[1] \n","    w_skew[1, 2], w_skew[2, 1] = -w[0], w[0] \n","    return w_skew\n","\n","\n","def parameterize_rotation_matrix(R):\n","    # Parameterizes rotation matrix into its axis-angle representation\n","    _, _, Vt = np.linalg.svd(R - np.eye(3))\n","    v = Vt[-1, :] # V is the last row of Vt\n","    vHat = np.array([R[2, 1]-R[1, 2], R[0, 2]-R[2, 0], R[1, 0]-R[0, 1]])\n","    cosTheta, sinTheta = (np.trace(R)-1)/2, v@vHat/2\n","    theta = np.arctan2(sinTheta, cosTheta)\n","    \n","    if (np.abs(theta) < 1e-5): # small rotation\n","        w = (1/2) * vHat\n","        return w, theta\n","    w = theta * v\n","    wNorm = np.linalg.norm(w)\n","    if (wNorm > np.pi):\n","        w = (1 - (2*np.pi/wNorm)*(np.ceil((wNorm-np.pi)/(2*np.pi)))) * w\n","    return w[:, None], theta\n","\n","\n","def deparameterize_rotation_matrix(w):\n","    # Deparameterizes to get rotation matrix\n","    theta = np.linalg.norm(w)\n","    wSkew = skew(w)\n","    I = np.eye(3)\n","    if (np.abs(theta) < 1e-5): # small rotation\n","        R = I + wSkew\n","        return R\n","    R = np.cos(theta)*I + sinc(theta)*wSkew + (((1-np.cos(theta))/(theta**2)) * np.outer(w, w))\n","    return R\n","\n","def data_normalize(pts):\n","    # Input:\n","    #    pts - 3D scene points\n","    # Outputs:\n","    #    pts - data normalized points\n","    #    T - corresponding transformation matrix\n","    dim = pts.shape[0]\n","    pts_homo = homogenize(pts)\n","    mux, muy, muz, varx, vary, varz = np.mean(pts[0, :]), np.mean(pts[1, :]), np.mean(pts[2, :]), np.var(pts[0, :]), np.var(pts[1, :]), np.var(pts[2, :])\n","    s = np.sqrt(3/(varx + vary + varz))\n","    T = np.array([[s, 0, 0, -s*mux], [0, s, 0, -s*muy], [0, 0, s, -s*muz], [0, 0, 0, 1]])\n","    pts_tr_homo = T @ pts_homo # perform transformation\n","    pts_tr = dehomogenize(pts_tr_homo)\n","    return pts_tr, T\n","\n","def normalize_with_cov(K, x, covarx):\n","    # Inputs:\n","    #    K - camera calibration matrix\n","    #    x - 2D points in pixel coordinates\n","    #    covarx - covariance matrix (2*2)\n","    #\n","    # Outputs:\n","    #    pts - 2D points in normalized coordinates\n","    #    covarx - normalized covariance matrix\n","    # project to normalized coordinates\n","    n = x.shape[1]\n","    K_inv = np.linalg.inv(K)\n","    \n","    x_homo = homogenize(x)\n","    pts_homo = K_inv @ x_homo\n","    pts = dehomogenize(pts_homo)\n","\n","    # propagate cov matrix\n","    J = np.array([[K_inv[0,0], K_inv[0,1]],[0, K_inv[1,1]]])\n","    # J = K_inv[:2, :2]\n","    for j in range(n):\n","        covarx[2*j:2*j+2, 2*j:2*j+2] = J @ covarx[2*j:2*j+2, 2*j:2*j+2] @ J.T\n","    return pts, covarx\n","\n","def partial_x_hat_partial_w(R, w, t, X):\n","    # Compute the (partial x_hat) / (partial omega) component of the jacobian\n","    # Inputs:\n","    #    R - 3x3 rotation matrix\n","    #    w - 3x1 axis-angle parameterization of R\n","    #    t - 3x1 translation vector\n","    #    X - 3D inlier point\n","    #\n","    # Output:\n","    #    dx_hat_dw -  matrix of size 2x3\n","    # get dxdXrot\n","    # print(X.shape, R.shape, w.shape, t.shape)\n","    w = w[:, 0]\n","    t = t[:, 0]\n","    X = X[:, 0]\n","\n","    x_proj =  dehomogenize(R @ X + t) \n","    Xrot = R @ X\n","    wHat = Xrot[2] + t[2]\n","    dx_hat_dXrot = np.array([[1/wHat, 0, -x_proj[0]/wHat],[0, 1/wHat, -x_proj[1]/wHat]])\n","\n","    # get dXrotdw\n","    theta = np.linalg.norm(w)\n","    if (np.abs(theta) < 1e-5):\n","        dXrot_dw = skew(-X)\n","    else:\n","        s = (1-np.cos(theta))/(theta**2)\n","        ds_dtheta = (theta*np.sin(theta) - 2*(1-np.cos(theta)))/(theta**3)\n","        dtheta_dw = (1/theta)*w.T\n","        xSkew = skew(-X)\n","        wSkew = skew(w)\n","        dXrot_dw = sinc(theta) * xSkew + \\\n","                    np.cross(w, X)[:, None] * d_sinc(theta) * dtheta_dw + \\\n","                    np.cross(w, np.cross(w, X))[:, None] * ds_dtheta * dtheta_dw + \\\n","                    s * ((wSkew @ xSkew) + skew(-(np.cross(w, X))))\n","\n","    # multiply by chain rule\n","    dx_hat_dw = dx_hat_dXrot @ dXrot_dw\n","    return dx_hat_dw\n","\n","\n","def partial_x_hat_partial_t(R, t, x_norm, X):\n","    # Compute the (partial x_hat) / (partial t) component of the jacobian\n","    # Inputs:\n","    #    R - 3x3 rotation matrix\n","    #    t - 3x1 translation vector\n","    #    x_norm - 2D projected point in normalized coordinates\n","    #    X - 3D inlier point\n","    #\n","    # Output:\n","    #    dx_hat_dt -  matrix of size 2x3\n","    t = t[:, 0]\n","    X = X[:, 0]\n","    x_norm = x_norm[:, 0]\n","\n","    Xrot = R @ X\n","    wHat = Xrot[2] + t[2]\n","    dx_hat_dt = np.array([[1/wHat, 0, -x_norm[0]/wHat],[0, 1/wHat, -x_norm[1]/wHat]])\n","    return dx_hat_dt\n","\n","def compute_cost(P, x, X, covarx):\n","    # Inputs:\n","    #    P - normalized camera projection matrix\n","    #    x - 2D ground truth image points in normalized coordinates\n","    #    X - 3D groundtruth scene points\n","    #    covarx - covariance matrix\n","    #\n","    # Output:\n","    #    cost - total projection error\n","    X_homo = homogenize(X)\n","    x_img_proj_homo = P @ X_homo\n","    x_img_proj = dehomogenize(x_img_proj_homo) \n","    n = x_img_proj.shape[1]\n","    epsilon = x - x_img_proj\n","    cost = 0\n","    for j in range(n):\n","        covarxj, epsilonj = covarx[2*j:2*j+2, 2*j:2*j+2], epsilon[:, j]\n","        cost += epsilonj.T @ np.linalg.inv(covarxj) @ epsilonj\n","    return cost\n"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"aBKG-OG7Uozc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameterized rotation matrix is equal to the given value +/- 1e-08: True\n","Deparameterized rotation matrix is equal to the given value +/- 1e-08: True\n","Computed partial_x_hat_partial_w is equal to the given value +/- 1e-08: True\n","Computed partial_x_hat_partial_t is equal to the given value +/- 1e-08: True\n"]}],"source":["# Unit Tests (Do not change)\n","\n","# parameterize and deparameterize unit test\n","def check_values_parameterize():\n","    eps = 1e-8  # Floating point error threshold\n","    w = np.load('unit_test/omega.npy')\n","    R = np.load('unit_test/rotation.npy')\n","    w_param, _ = parameterize_rotation_matrix(R)\n","    R_deparam = deparameterize_rotation_matrix(w)\n","\n","    param_valid = np.all(np.abs(w_param - w) < eps)\n","    deparam_valid = np.all(np.abs(R_deparam - R) < eps)\n","\n","    print(f'Parameterized rotation matrix is equal to the given value +/- {eps}: {param_valid}')\n","    print(f'Deparameterized rotation matrix is equal to the given value +/- {eps}: {deparam_valid}')\n","\n","# partial_x_hat_partial_w and partial_x_hat_partial_t unit test\n","def check_values_jacobian():\n","    eps = 1e-8  # Floating point error threshold\n","    w = np.load('unit_test/omega.npy')\n","    R = np.load('unit_test/rotation.npy')\n","    x = np.load('unit_test/point_2d.npy')\n","    X = np.load('unit_test/point_3d.npy')\n","    t = np.load('unit_test/translation.npy')\n","    dx_hat_dw_target = np.load('unit_test/partial_x_partial_omega.npy')\n","    dx_hat_dt_target = np.load('unit_test/partial_x_partial_t.npy')\n","\n","    dx_hat_dw = partial_x_hat_partial_w(R, w, t, X)\n","    dx_hat_dt = partial_x_hat_partial_t(R, t, x, X)\n","    w_valid = np.all(np.abs(dx_hat_dw - dx_hat_dw_target) < eps)\n","    t_valid = np.all(np.abs(dx_hat_dt - dx_hat_dt_target) < eps)\n","\n","    print(f'Computed partial_x_hat_partial_w is equal to the given value +/- {eps}: {w_valid}')\n","    print(f'Computed partial_x_hat_partial_t is equal to the given value +/- {eps}: {t_valid}')\n","\n","check_values_parameterize()\n","check_values_jacobian()"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"P_f7g3nKUozd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial iteration-0 Cost: 902.217482914  Avg cost per point: 21.481368640817724:\n","iter: 001  Cost: 54.626658073  Avg cost per point: 1.3006347160320142\n","iter: 002  Cost: 54.498614462  Avg cost per point: 1.2975860586128585\n","iter: 003  Cost: 54.498595578  Avg cost per point: 1.2975856090041074\n","iter: 004  Cost: 54.498595577  Avg cost per point: 1.2975856089686546\n","took 0.298404 secs\n","w_LM = \n","[[ 1.34089787]\n"," [-0.03061548]\n"," [ 1.41223214]]\n","R_LM = \n","[[ 0.28041958 -0.68901753  0.66829612]\n"," [ 0.65940811 -0.36765957 -0.65574948]\n"," [ 0.69752835  0.62456487  0.35124481]]\n","t_LM = \n","[  5.78161116   7.32996718 175.86386778]\n"]}],"source":["def get_jacobian(R, w, t, x_norm, X):\n","    # get jacobian w.r.t. w and t\n","    n = X.shape[1]\n","    J = np.zeros((2*n, 6))\n","    t = t[:, None]\n","    for j in range(n):\n","        Xj = X[:, j]\n","        x_normj = x_norm[:, j]\n","        Xj = Xj[:, None]\n","        x_normj = x_normj[:, None]\n","        dxj_dw = partial_x_hat_partial_w(R, w, t, Xj)\n","        dxj_dt = partial_x_hat_partial_t(R, t, x_normj, Xj)\n","        J[2*j:2*j+2, :3], J[2*j:2*j+2, 3:] = dxj_dw, dxj_dt\n","    return J\n","\n","def get_epsilon(P, X, x):\n","    x_proj_homo = P @ homogenize(X) # prepare epsilons and lambda\n","    x_proj = dehomogenize(x_proj_homo)\n","    epsilon = x - x_proj\n","    return epsilon\n","\n","def estimate_camera_pose_nonlinear(P, x, X, K, max_iters, lam):\n","    # Inputs:\n","    #    P - initial estimate of camera pose\n","    #    x - 2D inliers\n","    #    X - 3D inliers\n","    #    K - camera calibration matrix\n","    #    max_iters - maximum number of iterations\n","    #    lam - lambda parameter\n","    #\n","    # Output:\n","    #    P - Final camera pose obtained after convergence\n","    n_points = X.shape[1]\n","    covarx = np.eye(2 * n_points)\n","    R, t = P[:3, :3], P[:3, 3]\n","    C = -R.T @ t\n","    C = C[:, None]\n","    # normalize 3d points and the projection matrix\n","    X, U = data_normalize(X)\n","    x, covarx = normalize_with_cov(K, x, covarx)\n","    C_dn = dehomogenize(U @ homogenize(C)) \n","    t = -R @ C_dn\n","    # P[:3, :3], P[:3, 3] = R, t[:, 0] # don't do assignment using pointers! Re-assign a new one!\n","    P = np.hstack((R, t))\n","    x_proj_homo = P @ homogenize(X) # prepare normalized projections, epsilons, and lambda\n","    x_proj = dehomogenize(x_proj_homo)\n","    epsilon = x - x_proj\n","\n","    # estimate camera pose (calibrated)\n","    cost = compute_cost(P, x, X, covarx)\n","    print(f\"Initial iteration-0 Cost: {cost:.09f}  Avg cost per point: {cost / n_points}:\")\n","    for i in range(max_iters):\n","        R, t = P[:3, :3], P[:3, 3]\n","        w, _ = parameterize_rotation_matrix(R) # compute jacobians\n","        # print(\"Getting jacobian\")\n","        J = get_jacobian(R, w, t, x_proj, X)\n","        while (True):\n","            A = J.T @ np.linalg.inv(covarx) @ J + lam * np.eye(6) # solve delta\n","            b = J.T @ np.linalg.inv(covarx) @ epsilon.reshape(-1, order=\"F\")\n","            delta = np.linalg.inv(A) @ b\n","            w_0 = w + delta[:3][:, None]\n","            t_0 = t + delta[3:]\n","            # print(\"w, t, delta\")\n","            # print(w, t, delta)\n","            R_0 = deparameterize_rotation_matrix(w_0) # project and re-calculate epsilon\n","            P_0 = np.hstack((R_0, t_0[:, None]))\n","            epsilon_0 = get_epsilon(P_0, X, x) # get 2*n updated epsilon\n","            cost_0 = compute_cost(P_0, x, X, covarx)\n","            if (cost_0 >= cost):\n","                lam *= 10\n","                # print(\"Shouldn't go here\")\n","                continue\n","            else:\n","                # print(\"One update!\")\n","                P = P_0\n","                epsilon = epsilon_0\n","                lam = lam / 10\n","                prev_cost = cost\n","                cost = cost_0\n","                break\n","        print(f'iter: {i + 1:03d}  Cost: {cost:.09f}  Avg cost per point: {cost / n_points}')\n","        if (1 - cost_0/prev_cost < 1e-10):\n","            break\n","\n","    # denormalize projection estimate\n","    C_norm = (-P[:, 0:3].T @ P[:,-1])[:, None]\n","    C = np.linalg.inv(U) @ homogenize(C_norm)\n","    t = -P[:, 0:3] @ dehomogenize(C)\n","    P = np.hstack((P[:, 0:3], t))\n","    return P\n","\n","# LM hyperparameters\n","lam = .001\n","max_iters = 100\n","\n","tic = time.time()\n","P_LM = estimate_camera_pose_nonlinear(P_linear, x, X, K, max_iters, lam)\n","# P_LM = LM(P_linear, x, X, K, max_iters, lam)\n","w_LM, _ = parameterize_rotation_matrix(P_LM[:, 0:3])\n","toc = time.time()\n","time_total = toc-tic\n","\n","# display the results\n","print('took %f secs'%time_total)\n","print('w_LM = ')\n","print(w_LM)\n","print('R_LM = ')\n","print(P_LM[:,0:3])\n","print('t_LM = ')\n","print(P_LM[:,-1])\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":false,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
